
## Creating iDumb the Meta Framework into these structure

- This is going to be make as a meta plugin for OpenCode (install from client side of the users to use in any project with other popular spec-drive development framework like GSD and Speckit)  >> people can install for any project
- the one contain here is just for your references of what work and what don‚Äôt ‚Üí learn from  not using this `.opencode/plugins/ version of project-specific` anymore >>> (you can learn from your past conversation here ‚Üí>> full of flaws and hallucination `.frame-work-archive/last-session-hallucination.md` >>  shift to this in this new work space as >>  at `/Users/apple/Documents/coding-projects/idumb`

---

- To create plugin correctly you must make sure‚Üí can you  read this https://opencode.ai/docs/plugins/ ‚Üí as because I found there is template for creating plugin https://github.com/zenobi-us/opencode-plugin-template/?tab=readme-ov-file ‚Üí but it deprecated and make direction into  https://github.com/zenobi-us/bun-module

## Shift in concepts and approaches (core values = same)

### Core concepts:

1. CLI tools of Plugin for OpenCode (later other) >> acting as wrappers other popular software development frameworks (starting with BMAD, Speckit and other spec-drive), GSD, through providing automatic and enhanced tools (agent‚Äôs tools, CLI tools and as scripts)  so that the frameworks are activated with these concepts:
    1. Intelligent Automation  and improve app development success rate by following  and even enhancing the wrapped frameworks‚Äô guardrails and governance ‚Üí that  make possible with the following 
        1. allowing multiple hierarchy auto governance and handoff artifacts between primary agents, agents and subagents ‚Üí to intelligently decide by coordinator to run in parallel  or sequential >>>  
        2. keeping track and validate of guardrails concepts hierarchically and intelligently with supportive tools to transform guardrails and governance to hierarchy, meta tada and machine detectable >> validate, match, event watch, auto hooks and recovery backing >>> making sure all controlled governance entities are tracked and self-remediated 
    2. advanced context (the .idumb-brain) + boosting expertise, accuracy (preventing drift, hallucination, ready to confront human dev to prevent incompletion or bad practices) of agents:
        1. Advanced context : extensively and aggressively  treat context into these (as for improving the above mentioned)
            1. context classification: codebase, dev sessions, governance document and artifacts, workflows between agents >>> provide the correct tools use for search context, boost reasoning of agents  between con text
            2.  hierarchy + relationship: making context into >>> cognitive processor to agents  
            3. metadata, id, strict numbering, controlled with frontmatter and naming convention >>> making tracking of context easier
            4.  purging stale and drift context with the combination techniques + forced date and time stamps
        2. boosting expertise, accuracy >> agents act as experts that auto governance with domain-specific and providing user‚Äôs with experts viewpoints
            1. Intelligence boosting with ‚Äúenforced thinking frameworks‚Äù ‚Üí think of the framework that different types of agents vs. different tasks, phase of dev, types of project vs. complexity, greenfield or brownfield etc >>> these framing will be enforce into the above context, across types, making reasoning valid
            
            ## Under a scope of one particular project it looks like this (so this is my comment for how the previous AI agent did wrongly and it is based on the old-time approach for my specific project >>> but now as we approach this as a plugin >>> these needs significantly more well-crafted thinking
            
            ```markdown
            # `THE ABSOLUTE RESOLUTIONS` : ORDERS & PRIORITY AND ORDERS + HIERARCHY + RELATIONSHIP, COLLABORATION AND INTEGRATION  + GRANULAR AND INCREMENTAL GOVERNANCE AND TESTING + DOMAIN-SPECIFIC
            
            <aside>
            üí°
            
            The above are the keywords THAT  because not being applied throughout the tasks, workflows at every levels, approaches ‚Üí lead to failures in multiple aspects. They can be elaborated as below ‚Üí hence, all of the 4 AI agents approach PLUS you and your ultimate understanding  has fail to catch. So base on my below explanation and at some point I made the correction but I have not fully do so; as so many other lacking points base on these keywords are not really framed under here; which require you to go over all sections, correct them and add more of. 
            
            </aside>
            
            ## PRIORITY AND ORDERS, INTEGRATION OF GRANULARITY AND INCREMENTAL GOVERNANCE
            
            1. Not only the most important, but this is going to be the starting point. What most important point; the starting entry of deciding whether the remediation is a success or not =  the migrated framework of whatever to OpenCode native must be recognize by OpenCode and from there they are readable and be activated by the agents in OpenCode ‚Üí this also means direct accounts for this and the success of the framework in general is equal to ‚ÄúComplete in-deep understanding of OpenCode Concepts, not one, not as individuals, but across, and hierarchical concepts
            2. At the same accord, how can you and the meta framework remediation can build a successful native OpenCode feat orchestrating BMAD Beast-mother-fuking-mode editon ‚Üí when hell you don‚Äôt fundamentally understand how the original work (not mere surface understand but very thorough and in-depth, across domains kind of comprehensions) ‚Üí as so, the purpose of my customized `_bmad-ext-module` is a total lost  conception ‚Üí the formation of an adaptive OpenCode version will, for sure fail, let alone making any advanced edition. So this major check point hit multiple sections of framing the understanding down there creating a fact that ‚Üí `No you dont understand this at all` ‚Üí after accessing all of my feedbacks ‚Üí please do trace, correct and imrpove
            3. From number 1 we should direct to a more both, strategical and tactical approach of ‚Äúincremental-approach‚Äù and ‚Äúone-at-a-time‚Äù ‚Üí meaning introducing one piece at a time ‚Üí test if it works in OpenCode (by giving the most challenging testing that I will apply with multiple use cases in the Open Code platform)  ‚Üí only once it is recognize and be used by the agent then we proceed the next in incremental manner, meaning testing the combo in multiple use cases and branch them into horizontal nodes.
            
            ## HIERARCHICAL ORDERS + COLLABORATIVE RELATIONSHIPS + INTEGRATION + GRANULAR APPROACH + DOMAIN-SPECIFIC
            
            1. The concepts of hierarchical orders (from higher phase ‚Üí lower phases then in which phase contains their multi-step-workflows . The hierarchy also means which entities govern over which ones and their responsibilities);  and the concepts of collaborative relationships and integrations  (meaning there are  entities working as frameworks of order sequences. These may not necessarily suit into a particular hierarchy and they can be applied across levels of a hierarchy. HOWEVER, as when such thing is applied to it will execute its sequential orders ‚Üí hence demonstrating  `integration` and `collaboration.`  ) ; domain-specific concepts (this keyword can be understand under the scopes of specialist responsibilities and constraints, giving the conditions to etc ).  The POINT HERE IS ‚Üí SUCH CONCEPTS I MENTIONED ABOVE ARE MET IN MULTIPLE ASPECTS  OF NOT ONLY THIS META FRAMEWORK BUT THE WHOLE PROJECT ITSELF ‚Üí ‚Üí 
                1. Take `governance workflow`  (this is the by-step orders and domain-specific to govern something) in BMAD as an example; this can be executed by `bmad-master-agent` the highest level coordinator and have this master-coordinator  to validate a particular EPIC completion and health ‚Üí he will first not going to execute the work but check the sprint-status ‚Üí but as the sprint-status shows 100% completion ‚Üí he then, because of its role could not just pass the status to user but must do the governance job, he must be sure that the status of completion reflects reality in the codebase with evidences. However as his role would not allow direct executions and he also understand also the nature of the workflow involve not just some simple steps of reading a few code files ‚Üí Though he can definitely delegate this particular task to `dev-agent`, he should not. He would rather delegate this to `bmad-sprint-manager`-agent of team A and `bmad-sprint-manager-agent` of team B so that he can both relatively govern and validate in granularity and improve productivity as  both team A and B can run in parallel and as `bma-sprint-manager` agent can delegate in inner cycles of `analyst-agent` for investigation, or `architect-agent` to check for validation of architecture and of course to `dev-agent` to correct his claimed 100% completion but at only 70% for example. I hope the above example I gave demonstrate my point exactly. And be sure to understand this is one of many examples, and the concepts are ubiquitous throughout
            2. On the same notes ‚Üí partial understanding is worse than `not understanding at all` . This means I would appreciate that you say a certain point is unclear, or totally confess that it is out-scope and suggestions for more pre-works before jumping to the intended. Because partial understanding can disguise in as total understanding and usually be skipped by me ‚Üí and when stacked up it is extremely dangerous to the point of no way to revert. And this is proven again in your understanding and capture as reasons for failures - and why I bring this points here because most of them are because of lacking both horizontal and vertical both depth and across-domains understanding nor knowing the priority and order of integrations. These are the examples:
                1. You mentioned about `human readable document` at first, it sounds correct ‚Üí but now when I read again, it is not because as your understanding you claim the original BMAD framework does not work for agents ‚Üí but in fact it does ‚Üí and this brings to the point that agents  or workflows when not given enough specific details tend will never work.
                2. as when you mentioned one of my methodology `less for more` ‚Üí at first it sounds like you understand ‚Üí but you understand it under few shallow spectacles and when applying to the point you limit the maximum_step of agents is totally disastrous. Because for agentic works to truly work, and in this case cycles within cycles the maximum_step in certain case should not be given or can be hundreds - as for iterative executions can favor accuracy and improve quality while limited these will tend to make agents lazy
                3. the same disastrous note for some stupid limitation (like only allow certain agents to call agents ‚Üí these designs are completely wreck the inner cycles of loops or the prevention of todo tasks will crash the planning mindset of agents) and governance without context (this can extremely dumb down the agents as for not knowing what phase of the project it is to judge health score on the whole ‚Üí hallucinate the rest of the following flows that execute patches rather than letting the current phase execute as the current phase is foundational recovery that contains more meticulous planning for such efforts rather than applying trashy patches.    
                4. this partial understanding also clearly demonstrates through all the approach is for the last phase phase-4: the ‚Äúimplementation‚Äù focus and lose total control over the nature of cross-phase remediation, completion and alignment of the project ‚Üí for example, certain even happens like realization of a superior architecture design can shift the plan to remediate architecture with additional ADR- ‚Üí now that the phase 2 must be first executed and consolidated before the lower phase can continue
            
            ## COMPLETE LACKING OF THE FOLLOWING CONCEPTS: `Context-first`, `Expert-skeptic-mode`, `prevention of hallucination and drift`
            
            As I have said above of the `happy-path` mode, many of the failures of the previous team has fail to design any concepts that facilitate the above (I do not mean just agent profile, but these 3 must be communicated across other concepts as well to make sure they should work as they need to)
            
            - Context-first ‚Üí meaning in many ways, at any levels of work ‚Üí agents are expected to shape their context, understanding to not jump right to the `execution.` Context-first also means knowing what kind of context as of consume what worth and valid. This concept first also plays a significant role in improve efficiency of work when agents understanding of the context, they will use `TODO`  tasks list to organize their workflow; and as for you, you will prepare a master plan with tasks of tracking entities‚Ä¶ these are a lot more but be aware for such thing is also one of the priority
            - `prevention of hallucination and drift` is also extremely lacking as this has not expanded throughout workflows, lacking the multiple facets of the nature of cross-worflows, cross-phase, and event-watch between human user and the agent‚Äôs conversation when the workflows are executed
            - `Expert-skeptic-mode` this and the up two are closely have impacts to each other because as for this one works this need to automatically initiate the conversation with context-first ‚Üí ready to recorrect and stop me (the human user) from not venturing into certain point; or by having `prevention of hallucination and drift` will stop it from a dumb down decision to that block developments, because at this project, knowing how to hierarchically progress meaning to weigh between efficiency, practicality and coverage as some dumb decision trying to split god stores or god components first can really make the clean up EPIC delayed as the after-match of splitting god components are often the patching remediation of broken import exports and what worse is that some of the god components are actually would be then removed by the cleaned up EPIC‚Äôs work
            
            ## ACKNOWLEDGEMENTS OF AI AGENTS
            
            meaning acknowledge limit of YOU (because as now working under a broken framework and also just an LLM)  and of the AI agents and sub-agents that we are going to design (they are of the same kinds, but optimistically by the success of this time meta framework integration we can improve these significantly) , both subjectively and objectively.
            
            1. Acknowledge the limit of ‚ÄúYOU‚Äù as an AI agent also using this framework with your team of other agents and sub-agents; that if accuracy and validation is not granularly check ‚Üí incremental stack up of ‚Äúfew-minor-inaccuracies‚Äù will become ‚Üí a huge pile of shitty work that does not know when and where to trace back from. 
            2. The number 1 also brings us to this point ‚Üí that I should not give a too complex (including cycles in cycles of loops and iteration) ‚Üí to expect a clean, and valid results ‚Üí this is true as no matter how strict validation, and self-governance rules flaws are still plenty
            3. Setting constraints when designing advanced, automatic triggered and concepts that are with ‚Äústrict governance‚Äù ‚Üí these, in single, has already trouble the whole meta framework if  not governance or validate granularly the combo of these 3 will be nightmare
            4. Though knowing that I, as human engineer can validate the work returned by these AI agents,  validating everything and reading every returned documents nor I should let ai agents returned a shorten versioned (as they would not sufficient to hand-off as context for accuracy of work) ‚Üí the major turning points that can make everything significantly more enhanced  coming from you, acting as exact coordinator that never execute but delegate and that  you must always start with the frame and keep it as master routing plan; always start with proposing these are the routines and cycles plan in concise langue ‚Üí only run delegation when allowed; and so for not only validating synthesizing the returned handoff  and artifacts/documents but also to synthesize them and output the core, essential, decisive key points that I can quickly consume and validate the completion more easily.  And so as the role as coordinator and orchestrator you play a huge factor for the success of the team as not only you should validate and monitor, but you must also guide and direct through these:
                1. assignments with guidance >> guidance here does not mean dictation: As for execution agents would not sufficiently track the hierarchical context ‚Üí you should guide them specifically on the previous cycles‚Äô ones by specify the sections and the areas to look at ‚Üí do not dictate means as you also can not confirm how something will exactly occur so every context preparation should be prepared as guidance of `probability` and `points of concern` rather than any absolute limitations
                2. always set the requirements, acceptance criteria, preparing them with check list of returned values, of definition of completion, of constraints and be absolutely clear about all boxes must be checked with provided evidence before return the work
                3. it is also true with the report ‚Üí tell them what expectations, style, format, key points etc for in-chat report (as for they will output in chat as their last `assistant message` . This is very important as highest level coordinator you could not consume every flow of reports returned hence a more condense version that bring the most valuable pieces of information are absolutely needed
                4. all above is particularly true when it comes to advanced synthesis cycle ‚Üí showing your agents sources of knowledge or guide for consumptions ‚Üí aid with brainstorming by giving them list and/or keeping them not repeating on the already generated concepts by always having your master tracking   
            
            ‚Üí So, it is all about `THE ABSOLUTE RESOLUTIONS`  that I mentioned above, because you and the agents do not manage the hierarchy, flow and order exactly as they should, the same things for not really understand X but claim full understand, walking `the happy path` (which must at all cost ignore out of your system - to always `act expert` act skeptic, extremely critical and ruthless perfectionist to never accept something as `done`, `completion`, or `claimed success` without any proof and evidence of work). And so many of the above points I mentioned play key values for the success
            ```
            
            ---
            
            ## Advanced context including these key concepts:
            
            - Forced hierarchy, relational, classification, auto purge impure context (stale, irrational, broken chained of id, series of numbering id into all aspects that these are wrapped to or as themselves >>> So to truly achieve just one sector you should be able to make whaever agents can succesfully do these:
                - Thinking in sequences, knowing which happened, by whom, which cycles etc ‚Üí think above delegate cycles of context gathering to synthesize most accurate context kinds of thing
                - the manipulation of making TODO spawn every time but make them support 3-level hierarchy with hooks to conditional bounce back
                - to which we have force mechanism of which to do first then next then loops back (these are true for everythings, can markdown, yaml, xml, json manipulate this state of hop reading for instance
                - the long-term context also >>> how by using just grep, or any tools of use that can manipulate meta data, relational data to form neuro link >>> enable this kind of appended weekly, even monthly archive that allow these kinds of feature (and as these happens during the very intensive project done by multiple teams) >>> of coruse these take very robust and fine-tuning later but I just give example of one extreme case so you can imagine and to research to really answer if this is possible  ‚Üí from the aspect of long-term brain, this complex project of the team when using idumb has append the very structural (that including meta data, synthesis of entities like user message, what happened, what agents, workflows, at which phase of the project, planning , id of them and so on) - but somehow the hook of idumb was not working as for purging poisoned broken context (as id metadata was ignored when broken) >>> now leaving just this exceeding windows context xml (or yaml or whatever format ) > let‚Äôs say by 500k of lines
                    - swarm of agents can still grep, glob, think critically >>> (of course by multiple iterations ) to tell what went wrong, at which day, who did that, which plan, phases and what chage >>> sufficient 400 lines report condense and impactful accurately addressed
                    - as for the win milestone very first is how this is installed and how
            
            SO i will make more specific as we building  but let‚Äôs you consume the what happen and also knowing more about what are there that I try to achieve so that you can conduct a research framework that look for what cater my ideas.
            
            ### Most frameworks are excellent and they are all capable of facilitate AI agent build corporate-level projects (that is why this is going to be the wrappers) ‚Üí until these happen
            
            1. Not all users = experts but why blocking great ideas and struggling them more with  things like ‚Äúarchitecture drift‚Äù, ‚Äúschema drift‚Äù, types ,interfaces and so many other more just because:
                1. they keep chatting with not intend-to-be-not-domain-specific agent at at the wrong ‚Äúagile phase‚Äù, or initiate manually the wrong ‚Äúworkflows‚Äù which make it drift from core governance artifacts etc  ???  Yes that will be a hell of experience for ambitious great ideas when using BMAD >>> 
                    1. With this everything will start with just 
                    2. 1 supreme_orchestrator, or any of the agent of the selected frameworks in the support list  - this orchestrator at any phase, does not need users to have to manually select the correct workflow slash command ; does not need users to concern what phase of epics, story, or all of the sort  to even start prompting >>> everything just runs. So to this to happen are these mechanism:
                        1. wrapper ‚Üí so needs cli tools to either using scripts or append one agent that handle this insert frontmatter yaml, configure the values, and parameters in agents, commands, writting SKILLS following standards, appended tools >>> all to manipulate the  auto loops, handoff, multi hierarchy loops and validation to both OpenCode and the framework‚Äôs. So this example can be found in the header of some agents in the codebase I am developing
                        
                        ‚Üí but as you can see that this is project-specfic ‚Üí but what we are about to do is that this agent will be appended to, and many other values must be rewrite by at the time agent when user run `init` - because this is more like base on what type of project, brown or greenfield ‚Üí a  very in-depth pre-run of codebase analysis etc 
                        
                        ‚Üí and as I said above about the enforce issues ‚Üí currently we are using the hooks by eventwatch subscription to events shown on OpenCode Plugin - but to make this next-level there are still much more I would want to research as below:
                        
                        - each events ‚Üí what can we manipulate through each using hook + what LLM will see at each turn ‚Üí are there ways to manipulate the agent to:
                            - consume specific codebase‚Äôs artifact (those md, yaml status , etc) BEFORE reading user‚Äôs prompt first (I guess not )- so it will be more load content from user‚Äôs prompt (it is if the conversation starter - so if prompt of user is clear without including context files then they all well ) ‚Üí so there will be these I want to know
                                - can we manipulate hooks to start delegate tasks and append context (meaning always sending replaced prompt at start ‚Üí for delegation then append users‚Äô prompt?
                                - it is  for conversation starter  but what about during conversation, what kinds of content, how llm see them every turn ‚Üí are there clear conversation turns each time context sent to LLM >>> because for this to be successful ‚Üí I need to find way to at least being able to mark and anchor turns in  session >>> as I observe agents tend to hallucinate after compact, and especially when it gets long  >> just being to force focus on the last 3-4 turns can make differences
                                - Because as far as you can see here
                                
                                ```markdown
                                /Users/apple/Documents/coding-projects/project-alpha-master/.opencode/plugins
                                /Users/apple/Documents/coding-projects/project-alpha-master/.opencode/plugins/lifecycle
                                /Users/apple/Documents/coding-projects/project-alpha-master/.opencode/plugins/lifecycle/beast-mode-orchestrator.ts
                                /Users/apple/Documents/coding-projects/project-alpha-master/.opencode/plugins/post-execution
                                /Users/apple/Documents/coding-projects/project-alpha-master/.opencode/plugins/post-execution/god-artifact-guard.ts
                                /Users/apple/Documents/coding-projects/project-alpha-master/.opencode/plugins/post-execution/state-sync-plugin.ts
                                /Users/apple/Documents/coding-projects/project-alpha-master/.opencode/plugins/pre-execution
                                /Users/apple/Documents/coding-projects/project-alpha-master/.opencode/plugins/pre-execution/brownfield-guard.ts
                                /Users/apple/Documents/coding-projects/project-alpha-master/.opencode/plugins/pre-execution/context-gathering-gate.ts
                                /Users/apple/Documents/coding-projects/project-alpha-master/.opencode/plugins/pre-execution/stale-artifact-guard.ts
                                /Users/apple/Documents/coding-projects/project-alpha-master/.opencode/plugins/architecture-enforcer.ts
                                /Users/apple/Documents/coding-projects/project-alpha-master/.opencode/plugins/context-first-compaction.ts
                                /Users/apple/Documents/coding-projects/project-alpha-master/.opencode/plugins/context-first-starter.ts
                                /Users/apple/Documents/coding-projects/project-alpha-master/.opencode/plugins/master-orchestrator.ts
                                ```
                                
                                - Though I have successfully change the innit command by making the command to compact replaced ‚Üí make compact hierarchical and linked with artefacts >>  it does not change much
                                - and next is to which extend can we manipulate this in-chat session conversation
                                
                                ---
                                
                                Ok I think that first ‚Üí as for I don‚Äôt want to scare you 
                                
                                ‚Äî
                                
                                /research actually even the old one does not really work as it should it does almost nothing as it say even it is project-specific so I will approach this project more like trial and errors more like a pack of concepts ‚Üí pack into plugin + CLI tool ‚Üí Then I will try in multiple case of different codebase ‚Üí if it is truly shows as the result should be then we will stack complexity upon. So again , though every things shown in the legacy plugin sound like works but even stay native  in the project >>> let‚Äôs alone injection to any other projects so to truly activate purified-context and idumb-brain i need a fact-based research
                                
                                - what events - what hooks -what can intercepts - and what agents read for
                                    - starting conversation
                                    - for its delegated cycles - what delegator read before and after completion
                                    - during conversation - every turn
                                    - after compact
                            
                            these first, do not give me fantasy research as above 
                            
                        
                    

## Handle these by phases - milestones success than next

[Phase 1: prototype and testing of the concepts](https://www.notion.so/2fa926f31a4d8080a890c22cb26a9b87?pvs=21)
## Currently I can‚Äôt install this anywhere in any project ‚Üí failure

pay attention to this time fix this:

- the init install must get users ‚Üí to the selection of by-step guides; detection of their project including
    - the appending ‚Äúconcepts‚Äù of us ‚Üí to global or project-based
    - the GSD framework https://github.com/glittercowboy/get-shit-done (again this is used as client-service at user‚Äôs project) ‚Üí that what they are and how the wrappers tend to do
        - hierarchy and types of concepts (documents? governance? artifacts? and concepts? so on..)
        - when we wrap something into what it does ‚Üí what the concepts changed etc
        - the absolute correct wrap non-breaking
    - there must be the scripts, tools as for configuration and settings

## Revamp the concepts by putting deep thoughts into this (and the dos and donts)

1. For the appending agents https://opencode.ai/docs/agents/  (study the configuration very carefully) - to ensure hierarchy, and accuracy of when and where they got called and by which other agents (not only of the appended but to the wrapped agents as well); so look more into the hierarchy manipulation concepts (knowing there are up to 3 level of cycles of delegations, and settings that use to manipulate them are mode: primary, all and subagents - subagents can‚Äôt call any other agents; but agents set at all can delegate multi level, but if agents are particularly just for being delegated make them subagents. And to manipulate subagents not being called manually by users make them hidden which is only for delegation tasks)  and there should be these agents (high-level only you must think more to make them valid)
    1. supreme_coordinator (top highest)
    2. high-level-governance ‚Üí doing the high and mid governance ‚Üí they must be able to auto append prompts  and system prompts or initiate commands to force a workflow for instance ; these are also the way for them to adapt new profile
    3. low-level-validator: there are all sort validation work but these will directly do the grep, list, glob, seaarch and keyword regrex or run tools and run test kind of things
    4. idumb-builder: this will run tools, folllow appended prompt and commands, will spawn initially to wrap context to intended framework in yaml frontmatter (of course following the hierarchy) + also literately edit the appended concepts to match to certain conditions and the project >>> there must be a very meticulous design for this that match nested levels and relationship. And during phases this want must be updated too
2. commands and CLI commands ‚Üí users will use these to initiate something - of course starting with init but not to make these overlapping with any others make sure they are all prefixed with `idumb` ‚Üí as for these can be used by for the rest
3. I know most of what you are going to created can fail desperately but at least the testing concepts for this prototype must work

## Dos and Donts for the OpenCode Plugin and as Framework wrapper:

 

| Concepts | DO | DONTS | RESEARCH + THINK ABOUT |
| --- | --- | --- | --- |
| As a Plugin to instal by users |   ‚Ä¢ Understand all the concepts of what is a plugin in OpenCode 
  ‚Ä¢ Understanding the concepts of OpenCode using as client-side - when users use it as a platform to develop project
  ‚Ä¢ Do understand the core concepts or what drive OpenCode as a platform to developer using agentic coding: `commands`, `agents`, `subagents` , `innate tools` , `customized tools`, `rules`, `skills,`  , `sessions` , `lsp server`, `mcp server`
  ‚Ä¢ understand the 2-level of OpenCode platforms, global setting, and project
  ‚Ä¢Understand extra concepts provided must click into either, both, or some of the above  |   ‚Ä¢ DON‚ÄôT assume anything related to OpenCode concepts as in this development environment
  ‚Ä¢ DON‚ÄôT misunderstanding to fall into :users using any core source code of OpenCode
  ‚Ä¢ DON‚ÄôT be creative to create something that DO NOT work in OpenCOde | look for pages online for the official instructions - Think about users use the plugins by installing them from github page, npm, pnpm, npx command |
| As a plugin that provide wrappers |   ‚Ä¢ if providing any extra concepts ‚Üí must align and point to the original framework in this case GSD
  ‚Ä¢ wrap the concepts into the framework with all the aware of the ecosystem, hierarchy, relationship, the flow, the governance of the intended framework |   ‚Ä¢ DON‚ÄôT assume anything work if not making any connection points
  ‚Ä¢ DON‚ÄôT assume it works if it does not reflect hierarchy, nor integration
  ‚Ä¢ DON‚ÄôT assume it works if it has no governance
  ‚Ä¢ DON‚ÄôT break any concepts (either core, short-live artifacts in any level of the intended frame-work) 
  ‚Ä¢  |   ‚Ä¢ Learn the concepts |
| Working with users‚Äô current project |   ‚Ä¢ DO understand the projects are varied, and that they are in multiple level of complexity and at any stage |   ‚Ä¢ DON‚ÄôT assume users will do this nor the others if there are not guidance, not one place but throughout |  |
| Work across concepts, into hierarchy, activate automation, engaging in governance and validation activities of the framework and under OpenCode concepts  |   ‚Ä¢ Do understand as hierarchy as above but also  how they behave when wrapped
  ‚Ä¢ DO understand to activate automation, validation and self-governance >>> there must be a meticulous approach to multi-level and cross-concepts integration points  |   ‚Ä¢ DON‚ÄôT assume that agent workflow get immediate constitute or obey to with just a rule in one place. Enforcement must not be scattered and unthoughtful
  ‚Ä¢ DON‚ÄôT assume that what you introduce work ‚Üí must ensure the agent of the project consume it at not only the start of the conversation but also pin it throughout |  |

  ## The definition of ‚ÄúIF IT WORKS‚Äù ‚Üí if check on all concepts you have created and any do of them can not check all of the list that its belong to ‚Üí they need improvement:

‚Üí Update with configuration that include what to call user, language ai to communicate with users, language of documents and artifacts (list of popular languages including english, vietnamese etc >>> the configuration will appended and be the first  read  at any session at all hierarchy ‚Üí as it should also include direction to (hierarchically) these:

- paths to status and state control
    - context of__
        - hierarchy of context__
    - state of ___
        - hierarchy of state___
    
- paths to documents and artifacts of: same of above

and the enforcements and general guidelines  ‚Üí currently as we are making GSD wrapper and as GSD has spawn their config.json (research for path) ‚Üí our method must trace and append accurately

- and make sure all installation work with any os. Interactive or none must all show status when completion
- at for now interactive does not work

Add new features belong to governance, automation governance, and context intelligence that relate to controlled of code file structures ‚Üí create new files and update update files watch ‚Üí manifest watch to prevent drift, overlapping, conflicts ‚Üí connect with atomic git hash control of GSD

- Feat 2: time and date stamp to frontmatter of short-live artifacts (thoese like plan, phase that generated by ai agents under GSD)  ‚Üí these are meta data controlled  ‚Üí these also registered to base the drift or conflict base on stale or conflict time and date

### The negotiable common list:

- [ ]  Any configuration that are not definite (different and controlled by users which are not in anyway belong to either GSD nor OpenCode innate values ) >>> they must be removed out and if they are needed for the concepts work find work-around
- [ ]  they must all obey to the above donts and dos
- [ ]  anything contribute  to runtime starting (starting a session) ‚Üí must be aligned to hierarchy and the automation to bounce back, loop, cycle and validation
- [ ]  if any introduced concepts contribute to the ‚Äúmid-session-activity‚Äù either they contribute to the automation or appending relevant commands or prompts and those must be made sure to consume by LLMs and aiding with anchoring context in hierarchy and relational level and acting as reminders of constitution and governance (supporting with the knowing of cycles, loops and their hierarchy)
- [ ]  if they contribute to the ‚Äúwrappers‚Äù of either OpenCode or GSD ‚Üí they must make sure un-break regulation, accuracy, completion, consistent and meta data controlled (these are often those concepts that make edit to yaml fronmatter )
- [ ]  if anything related to yaml fronmatter, json configuration, api schema control ‚Üí if they are to control OpenCode and that define by OpenCode API schema ‚Üí they must all be accurate

## The ‚Äúautomation‚Äù group

- [ ]  if they belong to the group of scripts, hooks, customized tools, and/or manipulations/modification of the OpenCode core >>> read their API do not mistaken with ‚Äúforking‚Äù the source code - those do not work ; these group need extra attention to ‚Äúnot-break-things‚Äù ‚Üí this group also must be careful for fallback strategy as they do not all times executed correctly
- [ ]  if the automation concepts depends on prompts, commands and LLMS read ‚Üí make sure to meticulously prompt with context help with clear requirements, acceptance criteria, meta data matching and check list (However do not over enegineer this as it may consume context exceeding the models)

### The status group and the core governance documents (either wrapper, self-added) must all

- [ ]  They are made by agent of the client‚Äôs project ‚Üí iterated (throughout not append), one version and stale check, id with meta data (regulated), detection of conflicts and stale
- [ ]  for foreseeable these types of documents or artifacts that may get long >>> come up with tools, script that activate chunk sequential chunk reading ‚Üí validating, and appending content in chunk (but still gain exact accuracy)

### The ‚Äúdelegations‚Äù and multi-cycle

- [ ]  all highest level (agents, coordinator) must all be controlled with enforce context-first, frameing with master tracking and hierarchy todo ‚Üí must delegate and ban all execution
- [ ]  the mid-level delegation can be depend on which phases ‚Üí but modifying code file (creating code files) should never be the permissions