# Domain Pitfalls

**Project:** iDumb Meta-Framework Plugin
**Researched:** 2026-02-02

---

## Critical Pitfalls

Mistakes that cause rewrites or major issues. **These are the lessons learned from the previous failed implementation.**

---

### Pitfall 1: OpenCode TUI Background Text Exposure

**What goes wrong:** Plugin outputs text that appears behind the TUI interface, creating visual artifacts and confusion.

**Why it happens:**
- Using `console.log()` or `console.error()` in plugins
- Unhandled promise rejections that print to stderr
- Synchronous errors during plugin initialization

**Consequences:**
- TUI becomes unusable
- User loses trust in plugin
- Hard to debug (text appears randomly)

**Prevention:**
- ALWAYS use `client.app.log()` for all logging
- Wrap all plugin code in try/catch with proper error handling
- Never use console.* methods

**Detection:**
- Test plugin in actual OpenCode TUI (not just tests)
- Watch for any text appearing outside the TUI panels

---

### Pitfall 2: Breaking GSD Compatibility

**What goes wrong:** Plugin modifies or replaces GSD files, causing GSD commands to fail or behave unexpectedly.

**Why it happens:**
- Modifying STATE.md, ROADMAP.md, or PROJECT.md directly
- Changing GSD command behavior incompatibly
- Conflicting agent names or command names

**Consequences:**
- GSD workflows break
- Users can't use GSD commands anymore
- Angry users who relied on GSD

**Prevention:**
- Use separate `.idumb/` directory for all iDumb state
- Prefix all commands with `idumb:` (not `gsd:`)
- Prefix all agents with `idumb-`
- Augment, never replace

**Detection:**
- Run full GSD workflow after installing iDumb
- Verify all `/gsd:*` commands still work

---

### Pitfall 3: Prototype-First Development

**What goes wrong:** Building features before understanding the platform, leading to fundamental design flaws.

**Why it happens:**
- Excitement to see something working
- Underestimating platform complexity
- "Figure it out as we go" mentality

**Consequences:**
- Everything looks like it works in isolation
- Integration reveals fundamental issues
- Complete rewrites needed

**Prevention:**
- Research FIRST, build SECOND (this document!)
- Test single feature in OpenCode before building more
- Incremental approach: one feature → test → next feature

**Detection:**
- Can you explain exactly how the platform works?
- Have you tested in the actual runtime environment?

---

### Pitfall 4: Context Poisoning

**What goes wrong:** Stale, contradictory, or invalid context accumulates, causing agent hallucination and drift.

**Why it happens:**
- No mechanism to detect stale context
- Append-only context without pruning
- Context from failed operations remains
- Broken chains of IDs and references

**Consequences:**
- Agents hallucinate based on outdated information
- Conflicting instructions in context
- "Pile of shitty work" (user's words)

**Prevention:**
- Timestamp all context artifacts
- Implement staleness detection (> 48 hours = stale)
- Use structured IDs for context chains
- Prune context before compaction

**Detection:**
- Check for references to non-existent files
- Look for contradictory instructions in context
- Monitor context age

---

### Pitfall 5: Happy Path Thinking

**What goes wrong:** Designing for success cases only, leading to fragile systems that break on real-world usage.

**Why it happens:**
- LLMs default to optimistic responses
- Testing with ideal scenarios
- Assuming users follow expected paths

**Consequences:**
- First edge case breaks everything
- Error handling is afterthought
- Users encounter silent failures

**Prevention:**
- Expert-skeptic mode enforcement
- Test error paths explicitly
- Assume things will fail, design for recovery

**Detection:**
- What happens when X fails?
- Have you tested with invalid input?
- What's the recovery path?

---

## Moderate Pitfalls

Mistakes that cause delays or technical debt.

---

### Pitfall 6: Over-Governance

**What goes wrong:** Too many validation gates block productive work.

**Why it happens:**
- Fear of drift/hallucination leads to excessive checks
- Every action requires approval
- Validators that never pass

**Prevention:**
- Configurable governance levels (light, moderate, strict)
- Advisory warnings, not blocking gates
- User override always available

---

### Pitfall 7: Limiting Agent Capabilities

**What goes wrong:** Artificial limits on `max_steps`, delegation, or TODO tasks cripple agent effectiveness.

**Why it happens:**
- Attempting to prevent runaway agents
- Misunderstanding "less is more" principle
- Copying patterns from other contexts

**Prevention:**
- User explicitly warned against this
- Allow flexible iteration (hundreds of steps if needed)
- Let agents plan with TODO tasks

---

### Pitfall 8: Scattered Configuration

**What goes wrong:** Configuration in multiple places leads to confusion about what's active.

**Why it happens:**
- Multiple config files (opencode.json, .idumb/config.json, etc.)
- No clear hierarchy
- Settings that conflict

**Prevention:**
- Single source of truth for iDumb: `.idumb/config.json`
- Document configuration hierarchy clearly
- Validate configuration on load

---

### Pitfall 9: Insufficient Handoff Artifacts

**What goes wrong:** Context doesn't survive session boundaries or compaction.

**Why it happens:**
- Not using compaction hooks
- Critical state only in memory
- No structured handoff format

**Prevention:**
- Use `experimental.session.compacting` hook
- Persist to `.idumb/brain/state.json`
- Define required handoff structure

---

### Pitfall 10: Assuming Claude's Training Data

**What goes wrong:** Building features based on Claude's "knowledge" that may be outdated or incorrect.

**Why it happens:**
- Claude responds confidently about outdated information
- Not verifying against official documentation
- Trusting training data over current reality

**Prevention:**
- Always verify with Context7 or official docs
- Date your sources
- Mark LOW confidence when only training data supports claim

---

## Minor Pitfalls

Mistakes that cause annoyance but are fixable.

---

### Pitfall 11: Inconsistent Naming

**What goes wrong:** Mixed naming conventions make discovery difficult.

**Prevention:**
- All commands: `/idumb:*`
- All agents: `idumb-*`
- All tools: `idumb-*`
- All files: `idumb-*.md` or `.idumb/`

---

### Pitfall 12: Missing Help Documentation

**What goes wrong:** Users don't know what commands exist or how to use them.

**Prevention:**
- `/idumb:help` command must be comprehensive
- Every command needs description in frontmatter
- Quick-start guide in README

---

### Pitfall 13: No Uninstall Path

**What goes wrong:** Users can't cleanly remove the plugin.

**Prevention:**
- `npx @idumb/create --uninstall` removes all files
- Document manual cleanup if needed
- Don't leave orphan files

---

## Phase-Specific Warnings

| Phase Topic | Likely Pitfall | Mitigation |
|-------------|----------------|------------|
| Plugin initialization | TUI background text | Test in actual TUI immediately |
| Agent hierarchy | Over-governance | Start with 2 levels, expand if needed |
| State management | Context poisoning | Implement staleness detection early |
| Command wrappers | Breaking GSD | Test GSD commands after every change |
| npm distribution | Installation failures | Test on clean machine/container |

---

## User's Explicit Warnings (from improving-the-prototype.md)

### DON'T Do These

| Anti-Pattern | User Quote | Mitigation |
|--------------|------------|------------|
| Assume understanding | "Partial understanding is worse than not understanding at all" | Verify every assumption |
| Happy path mode | "Must at all cost ignore out of your system" | Expert-skeptic enforcement |
| Limit max_steps | "Totally disastrous... hundreds if needed" | No artificial limits |
| Block TODO tasks | "Will crash the planning mindset of agents" | Allow full TODO usage |
| Skip testing | "One-at-a-time... test if it works in OpenCode" | Incremental validation |

### DO These

| Pattern | User Quote | Implementation |
|---------|------------|----------------|
| Context-first | "Shape context, understanding, not jump to execution" | Context gathering before action |
| Evidence-based | "Never accept done without proof and evidence" | Validation artifacts required |
| Hierarchical | "Cycles within cycles... coordinator delegates" | Agent hierarchy with clear delegation |
| Incremental | "Introducing one piece at a time" | Feature-by-feature with testing |

---

## Prevention Checklist

Before each development cycle:

- [ ] Have I tested in actual OpenCode TUI?
- [ ] Am I using `client.app.log()` not `console.*`?
- [ ] Does GSD still work after my changes?
- [ ] Is new state in `.idumb/` not GSD files?
- [ ] Have I verified claims against official docs?
- [ ] Is there a recovery path if this fails?
- [ ] Can users override any blocking behavior?
- [ ] Is there evidence of completion, not just claims?

---

## Sources

- User's explicit warnings: `_bmad-output/planning-artifacts/research/improving-the-prototype.md`
- Previous failure analysis: User feedback on failed prototype
- OpenCode patterns: `OPENCODE-INTERNALS-2026-02-02.md`
